\chapter{Literature Review}{\label{ch:lit_review}}

% Textual literature review (synthesis)
\section*{Textual Synthesis}
\noindent Interaction fidelity (high-fidelity setups with steering wheel and pedals) consistently improves training transfer, takeover performance, and user trust in automated driving scenarios. Gamification and in-car tasks maintain or increase driver vigilance; game performance metrics show promise as indirect measures of driver engagement and state monitoring. Physiological measures such as electrodermal activity (EDA) and pupil size provide objective evidence of engagement and vigilance when users perform AR/VR tasks in autonomous vehicles. Visual acuity—particularly dynamic visual acuity (DVA)—is linked to driving performance and can be effectively studied using VR simulations. Motion sickness and simulator sickness remain under-investigated in many studies and should be considered when designing longer-duration VR training protocols. Many studies rely on small, often homogeneous samples, limiting generalizability; future work should include more diverse and larger participant pools.

\vspace{6pt}
\section*{Tabular Summary of Reviewed Studies}
{\renewcommand{\arraystretch}{1.25}
\setlength{\tabcolsep}{4pt}
\tiny
\begin{longtable}{|p{0.18\textwidth}|p{0.16\textwidth}|p{0.22\textwidth}|p{0.18\textwidth}|p{0.20\textwidth}|}
\hline
\textbf{Title (Year)} & \textbf{Authors} & \textbf{Key Findings} & \textbf{Gaps / Limitations} & \textbf{Relevance / Context} \\ \hline
\endfirsthead

\multicolumn{5}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\textbf{Title (Year)} & \textbf{Authors} & \textbf{Key Findings} & \textbf{Gaps / Limitations} & \textbf{Relevance / Context} \\ \hline
\endhead

\hline \multicolumn{5}{r}{{Continued on next page}} \\ \hline
\endfoot

\hline
\caption{Summary of key prior research on VR and AR systems for driving and autonomous vehicle simulation.}
\label{tab:litreview}
\endlastfoot
Virtual Reality Tour for First-Time Users of Highly Automated Cars: Comparing the Effects of Virtual Environments with Different Levels of Interaction Fidelity (2021)~\cite{Harari2021} & Rayan Ebnali Harari, Richard Lamb, Razieh Fathi, Kevin Hulme & High-Fidelity VR with steering wheel/pedals improved automation trust, takeover time, and takeover quality vs. Low-Fidelity VR. & Participants expected takeover events, short 1‑hour sessions, limited generalization to SAE L3/L4. & Shows that high interaction fidelity boosts motor‑skill transfer in VR training for automated driving. \\ \hline
Feasibility of AR-VR Use in Autonomous Cars for User Engagements and its Effects on Posture and Vigilance During Transit (2023)~\cite{Muguro2023} & Joseph Muguro, Pringgo Widyo Laksono, Yuta Sasatake, Muhammad Ilhamdi Rusydi, Kojiro Matsushita, Minoru Sasaki & VR tasks kept users alert based on EDA and pupil size. Delay in hazard recognition < 1s. Mixed tasks improved posture. & Very small sample (15), limited scenarios, motion sickness not analyzed. & Physiological proof that VR/AR interactions help maintain vigilance in ADS. \\ \hline
User Monitoring in Autonomous Driving System Using Gamified Task: A Case for VR/AR In-Car Gaming (2021)~\cite{Muguro2021} & Joseph K. Muguro, Pringgo Widyo Laksono, Yuta Sasatake, Kojiro Matsushita, Minoru Sasaki & Gamified AR tasks didn’t hurt hazard detection. Game score trends help estimate user state. Gaze data showed focused attention. & VR simulation instead of real vehicle; small student sample (13). & Supports use of VR/AR gamification to track user state and maintain attention. \\ \hline
Driving Performance Evaluation Correlated to Age and Visual Acuities Based on VR Technologies (2020)~\cite{Hwang2020} & Sooncheon Hwang, Sunhoon Kim, Dongmin Lee & Dynamic Visual Acuity predicted unsafe driving better than Static VA. Poor DVA = higher lane deviation. & Small sample (65), VR differs from real driving, same thresholds for SVA/DVA. & Shows VR’s usefulness for testing how vision affects driving behavior. \\ \hline
VR‑based Dataset for Autonomous‑Driving System (2020)~\cite{Yao2020} & Shouwen Yao, Jiahao Zhang, Yu Wang & VR used to build a large and varied autonomous‑driving dataset with auto‑generated labels for 2D and 3D data. Human‑in‑the‑loop VR driving captured stereo video, LiDAR, GPS across many environments and conditions. & Accuracy limited by reliance on VR sensor models and physics; still differs from real‑world driving; realism constraints in simulation. & Helpful for generating large, consistent, low‑cost datasets to train and test autonomous‑driving algorithms in controlled scenarios. \\ \hline
The Effects of Age, Gender, and Control Device in a Virtual Reality Driving Simulation (2020)~\cite{Chang2020} & Wen‑Te Chang & Age strongly influenced VR driving/navigation performance; young participants outperformed seniors. Straight (easy) routes gave higher scores than curved (difficult) ones. Young males performed better than young females; seniors showed no gender difference. Handlebar device improved performance only in young users, not seniors. & Seniors adapted slowly to VR; only two task types; limited VR realism; control devices not designed specifically for seniors. & Useful for understanding how age, gender, and input devices affect VR driving performance—important for designing VR training or in‑car interfaces for diverse user groups. \\ \hline
Predicting Perceived Realism in Virtual Reality Driving Simulations Using Participants’ Personality Traits, Heart Rate Changes, and Risk Preference (2024) & Uijong Ju, Sanghyeon Kim & Psychopathy and Machiavellianism negatively correlated with perceived realism; heart rate increases and risky decision-making were positively correlated. Tree-based ML (random forest, gradient boosting) predicted perceived realism best when using significant offline features; online-only models showed different strengths. & Sample skewed toward young men; events occurred once per participant; moderate baseline realism due to lack of motion cues and complex traffic; limited generalizability. & Demonstrates how personality and physiological metrics predict perceived realism and offers ML methods to model realism — valuable for adaptive VR training and improving validity of driving simulations. \\ \hline
Quantitative Analysis of Cognitive Load Test While Driving in a VR vs Non‑VR Environment (2019)~\cite{Qadir2019} & Zeeshan Qadir, Eashita Chowdhury, Lidia Ghosh, Amit Konar & EEG‑based cognitive load comparison showed VR driving produced higher brain activation (prefrontal, frontal, parietal) and higher cognitive load across all driving actions. Proposed CIT2FS classifier achieved higher accuracy in VR (avg 86.1\%) vs non‑VR (78.9\%). VR improved classification of accident, steering, braking, etc. & Small participant pool (11); short 15‑min sessions; limited ecological validity; tested only one VR hardware setup; no qualitative user‑experience evaluation. & Shows VR induces stronger cognitive load and yields more accurate EEG‑based driver‑state classification, supporting VR’s value for studying cognitive load and training autonomous‑driving safety systems. \\ \hline
Comparison of Teleportation and Fixed‑Track Driving in VR (2019)~\cite{Lindal2019} & Páll J. Líndal, Kamilla Rún Jóhannsdóttir, Unnar Kristjánsson, Nina Lensing, Anna Stühmeier, Annika Wohlan, Hannes H. Vilhjálmsson & Teleportation caused significantly less simulation sickness and maintained more positive attitudes toward VR compared to fixed‑track driving. Heart‑rate patterns suggested higher mental effort during teleportation, but overall comfort was better. & Focused on locomotion comfort, not driving skill; urban exploration task, not a driving‑specific simulator; VR duration differences between groups influenced sickness. & Helps justify why VR training environments must carefully choose locomotion methods. Supports our claim that “comfortable VR motion” is essential before teaching driving skills in VR—reducing sickness improves training acceptance, user trust, and realism. \\ \hline
Driving Simulator Using Virtual Reality Tools Combining Sound, Vision, Vibration, and Motion (2024)~\cite{GilCarvajal2024} & Juan Camilo Gil‑Carvajal, Eun Soo Jo, Dong Chul Park, Wookeun Song, Cheol‑Ho Jeong & Multimodal VR driving simulator tested with sound (headphones vs loudspeakers), motion, and vibration. Motion + vibration significantly boosted immersion and powerfulness; motion contributed more than vibration. 64‑speaker ambisonics gave best sound‑localization accuracy; headphone‑based audio (no head‑tracking) performed worst. Sound reproduction method did not significantly change immersion/powerfulness. & Small sample sizes (10–20 per experiment); no individualized HRTFs; no head‑tracking in headphone playback; motion platform may introduce unintended vibrations; realism limited by recording setup and controlled scenarios. & Strong support for using multi‑sensory VR (motion + vibration + visuals) to achieve high‑immersion driving experiences. Helps justify including motion cues in our project and shows why audio‑localization fidelity matters for realism in VR driving simulations. \\ \hline
Evaluating VR Driving Simulation from a Player Experience Perspective (2017)~\cite{Walch2017} & Marcel Walch, Philipp Hock, Julian Frommel, David Dobbelstein, Katja Rogers, Michael Weber, Felix Schüssel & VR increased real‑world dissociation and was preferred by participants, but did not significantly improve immersion, presence, enjoyment, or driving performance compared to triple‑screen setups. VR caused slightly higher discomfort. Driving times were similar across both conditions. & Small sample (18 after exclusions); relied on racing‑game software; limited realism (no traffic, constrained track); VR HMD had smaller FOV; results based on self‑reported questionnaires; possible survey fatigue. & Useful for showing that VR is not automatically superior to flat‑screen simulators. Supports our argument that VR must be designed carefully—comfort, FOV, realism, and matching physical/virtual controls matter for effective training in autonomous‑driving contexts. \\ \hline
HMD‑Based VR Tool for Traffic Psychological Examination: Conceptualization and Design Proposition (2021)~\cite{Jurik2021} & Vojtěch Juřík, Václav Linkov, Petr Dečký, Sára Klečková, Edita Chvojková & Paper proposes a VR‑based system for traffic‑psychological exams using HMDs + eye‑tracking + haptic driving interface. Highlights that VR can measure complex driver traits like situational awareness, distraction, fatigue, and hazard perception more effectively than traditional tests. Emphasizes that VR enables controlled, repeatable scenarios and richer behavioural/physiological data. & Conceptual (not experimentally validated), no user study, no empirical performance data, proposed system not implemented, relies on future development of affordable ET‑enabled HMDs. & Useful as a theoretical foundation showing why VR is suitable for driver assessment, supporting our justification for using VR in automated‑driving research and training. Reinforces the value of eye‑tracking, haptics, and controlled VR environments. \\ \hline
Evaluation of the Training Effect of the Driving Simulator + VR on Driving School Trainees (2022)~\cite{He2022} & Chenxi He, Yiping Wu, Xiaohua Zhao, Yang Ding, Shuo Liu & Study with 119 driving‑school trainees showed strong improvements in reaction, knowledge, driving behaviour, and exam pass rates using a combined VR + simulator training system. & Limited to trainees; no long‑term retention or real‑world transfer tracking. & Strong evidence that VR + simulator fusion improves driving‑school outcomes and supports using VR for driver‑training effectiveness. \\ \hline
Analyzing the Inconsistency in Driving Patterns Between Manual and Autonomous Modes Under Complex Driving Scenarios with a VR‑Enabled Simulation Platform (2022)~\cite{Xu2022} & Zheng Xu, Yihai Fang, Nan Zheng, Hai L. Vu & VR‑based naturalistic platform + ML‑driven AV model compared human vs. AV behavior. AV maintained stable speed and low accident rate (<1\%), while humans hesitated and made unsafe maneuvers. 81\% of drivers intervened due to low trust. & AV struggled in new environments until ~60 iterations; TTC threshold unreliable; small sample (18); limited VR realism; only Level‑4 autonomy tested. & Shows VR is effective for analyzing human–AV trust, intervention behavior, and differences between human‑driven and autonomous patterns. \\ \hline
Electrogastrography in Autonomous Vehicles—An Objective Method for Assessment of Motion Sickness in Simulated Driving Environments (2021)~\cite{Trofimova2021} & Ekaterina Trofimova, Timo Koch, Thomas Ludwig & EGG reliably detected motion‑sickness onset in VR autonomous‑vehicle rides. Dynamic routes increased abnormal gastric rhythms and sweating; button‑press self‑reports matched physiological data. Heart rate was less useful. & Small sample; VR motion realism limits; only Level‑5 scenario tested; EGG requires careful sensor placement. & Shows VR can objectively measure passenger discomfort using physiological signals—useful for evaluating comfort in AV/VR driving research. \\ \hline
Stopping Behavior in a VR Driving Simulator: A New Clinical Measure for the Assessment of Driving (2005)~\cite{Schultheis2005} & Maria T. Schultheis, Lisa K. Simone, Emily Roseman, Richard Nead, Jose Rebimbas, Ronald Mourant & VR simulator captured detailed stop‑sign behavior differences between adults with and without acquired brain injury (ABI). ABI group showed more missed stops, longer learning curves, and different stopping distances. & Small sample (24); outdated VR hardware; focused only on stop‑sign behavior; excludes participants with simulation sickness. & Demonstrates VR’s ability to measure fine‑grained driving performance, supporting its use for assessing impaired or at‑risk drivers. \\ \hline
The Static and Dynamic Analyses of Drivers’ Gaze Movement Using VR Driving Simulator (2022) & Jiyong Chung, Hyeokmin Lee, Hosang Moon, Eunghyuk Lee & Compared novice vs. experienced drivers using VR + eye‑tracking. Novices had longer dwell times, longer fixations, narrower visual search, lower stationary gaze entropy, and simpler gaze‑transition patterns. Experienced drivers distributed gaze more evenly and showed higher gaze‑transition entropy, indicating richer situational awareness. & Small sample (23 male drivers); only intersection scenario tested; eye‑tracking at 30 Hz; only VR‑HMD; no diverse age groups or real‑road validation. & Shows how VR + eye‑tracking reveals differences in attention and hazard detection—useful for VR‑based training, risk assessment, and identifying at‑risk drivers. \\ \hline
Comparing VR and Non‑VR Driving Simulations: An Experimental User Study (2017)~\cite{Weidner2017} & Florian Weidner, Anne Hoesch, Sandra Poeschl, Wolfgang Broll & Compared 2D, S3D, and VR‑HMD using the Lane Change Task. Driving performance and physiological responses showed no major differences across display types. VR‑HMD caused significantly higher simulator sickness than S3D. & Older VR hardware (Oculus DK2); simple task may not show depth‑related differences; mostly young participants; limited vehicle‑physics realism. & Shows VR does not automatically improve performance but can increase sickness—important for selecting appropriate VR hardware and scenario design. \\ \hline
Effects of Neuro‑Cognitive Load on Learning Transfer Using a VR‑Based Driving System (2021)~\cite{Abdurrahman2021} & Usman A. Abdurrahman, Shih‑Ching Yeh, Yunying Wong, Liang Wei & VR driving simulator + sensors (eye‑tracking, pupil dilation, heart rate) showed cognitive load rises on complex routes. Harder routes caused larger pupil dilation, higher heart rate, and more mistakes. ML models reached ~97\% accuracy in classifying cognitive‑load levels. & Conducted only in VR; 98 inexperienced student drivers; sensor noise and missing data; no real‑world validation. & Shows VR + physiological sensing can objectively measure mental workload; useful for ADS training, difficulty analysis, and user‑state monitoring. \\ \hline
DReyeVR: Democratizing Virtual Reality Driving Simulation for Behavioural \& Interaction Research (2022)~\cite{Silvera2022} & Gustavo Silvera, Abhijat Biswas, Henny Admoni & Introduces DReyeVR, an open‑source VR driving simulator (Unreal + CARLA) with eye‑tracking, head‑tracking, mirrors, spatial audio, custom scenarios, logging, and ROS support. Low‑cost (<$5000) behavioural research platform. & Medium‑fidelity (no motion base); consumer VR hardware limits realism; Windows‑only SDK; lacks full behaviour‑transfer validation. & Highly relevant: enables flexible AV/driver behaviour studies, trust research, hazard‑scenario creation, and attention monitoring in VR. \\ \hline
Driving Simulator with VR Glasses for Evaluation of New Interior Concepts (2019)~\cite{Hartfiel2019} & Bert Hartfiel, Alexander Kroys, Nico Kruithof, Rainer Stark & Volkswagen built a dynamic VR simulator combining an HMD, motion platform, and adjustable physical mock‑up. Enables early interior/HMI evaluation with vestibular cues, realistic visuals, adjustable seats/dashboards, and synchronized audio/haptics. & Hard to calibrate motion compensation; HMD tracking issues on moving platform; consumer VR limits fidelity; no behavioural validation; costly engineering setup. & Shows how VR + motion + physical mock‑ups support early design, ergonomics testing, visibility checks, and interior‑concept validation for driving/AV research. \\ \hline
Freeway Traffic Safety Evaluation Using Virtual Reality: Focus on Compound Curve (2022)~\cite{Zhang2022} & Chi Zhang, Bo Wang, Yongchun Li, Lei Hou, Min Zhang, Changhe Liu, Zilong Xie & Built a VR‑based driving simulation + human–computer interaction safety platform to study compound‑curve freeway safety. Collected driver heart‑rate changes, steering‑wheel angle change rate, and driving‑trajectory deviation to compute a comprehensive safety index (H). VR allowed testing multiple curve geometries using orthogonal experiments; results identified which curve‑design factors significantly impact safety. & Limited to compound curves on Chinese freeway geometry; small participant pool; relies on simulator realism; physiological metrics can vary across individuals; no real‑world driving validation. & Relevant because it shows how VR driving simulations can evaluate risky road geometries, analyze driver stability, and measure physiological load—supporting VR as an effective tool for traffic‑safety assessment and design evaluation. \\ \hline
Rerun: Enabling Multi‑Perspective Analysis of Driving Interaction in VR (2022)~\cite{Goedicke2022} & David Goedicke, Harald Haraldsson, Navit Klein, Lunshi Zhou, Avi Parush, Wendy Ju & Introduces Rerun, a Unity‑based system that records VR driving interactions and allows full multi‑perspective replay (first‑person, third‑person, observer view). Enables detailed post‑hoc study of signalling, communication, and interaction between drivers, especially in multi‑user VR driving setups. & No built‑in behavioural validation study; relies on StrangeLand simulator; limited to visual replay (no physical cues); requires specific Unity asset (Ultimate Replay). & Useful for analysing driving communication, reconstructing participant interactions, and studying trust/attention in VR driving environments—supports high‑detail behavioural evaluation in VR driving research. \\ \hline
\end{longtable}}

\noindent The studies summarized in Table~\ref{tab:litreview} collectively indicate that interaction fidelity, physiological engagement monitoring, and gamification significantly influence driver training outcomes and user vigilance. These insights directly inform the system design of the proposed VR-based driving simulator presented in Chapter~\ref{ch:system_analysis}.